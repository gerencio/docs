# Apache Spark
## Descrição de Recursos
### Autor: Pedro Nakibar

  Feito em cima das bases do Hadoop, com o objetivo de ser mais rápido que o MapReduce. O Spark supera o Hadoop em algumas aplicações e é extremamente útil e veloz para algoritmos de aprendizado de máquina. O Spark também faz uso de armazenamento distribuído, podendo utilizar o sistema de arquivos distribuído do Hadoop para isso.
  É também dele o título de projeto com mais contribuidores da Fundação Apache, sendo ele o mais ativo da fundação e um dos mais ativos projetos em big data open-source do mundo.
  O Spark também é muito testado, mesmo sendo um projeto novo, lançado em 2014, ele teve uma adoção extremamente rápida pela comunidade, que como ele funciona em cima de tecnologias já existentes e utilizadas, foi muito fácil adaptar o ambiente já existente à nova tecnologia.
  Extremamente escalável, o Spark foi feito para ser distribuído e rodar em muitos nós para que seja melhor aproveitado, uma vez que ele funciona muito bem com dados na escala dos Petabytes.

